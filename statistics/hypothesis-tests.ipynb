{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cd487e-5b05-4487-82f0-172679fee968",
   "metadata": {},
   "source": [
    "<span style=\"color:#333333; font-size:24px; font-weight:bold\"> Compiled by <a href=https://github.com/cyterat style=\"color:#00b2b7;\">cyterat</a></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde3621-9733-4a64-b8c4-be6ad6a9f9db",
   "metadata": {},
   "source": [
    "__Practical considerations:__\n",
    "\n",
    "- __Appropriate sample size__: varies by test, but generally larger is better.\n",
    "\n",
    "- __Data quality__: minimal measurement errors and no missing data unless appropriately handled.\n",
    "\n",
    "- __Adherence to test assumptions__: normality, homogeneity of variances.\n",
    "\n",
    "- __Sampling__: Random sampling from the population of interest.\n",
    "\n",
    "- __Level of measurement__: Appropriate level of measurement for the chosen test, e.g. nominal, ordinal, interval, or ratio ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4cd69e-d00a-42f7-a416-07d4a58ed5ab",
   "metadata": {},
   "source": [
    "__Corrections__:\n",
    "\n",
    "- __Bonferroni Correction__\n",
    "    - Use case: When performing multiple independent hypothesis tests.\n",
    "    - Method: Divides the alpha level by the number of tests.\n",
    "    - Best for: Small number of comparisons, very conservative.\n",
    "- __Holm-Bonferroni Method__\n",
    "    - Use case: More powerful alternative to Bonferroni for multiple comparisons.\n",
    "    - Method: Step-down method that orders p-values from smallest to largest.\n",
    "    - Best for: When you need more statistical power than Bonferroni but still want strong control of Type I errors.\n",
    "- __False Discovery Rate (FDR) Corrections__\n",
    "    - a. __Benjamini-Hochberg Procedure__\n",
    "        - Use case: When you're willing to accept a certain rate of false positives to increase power.\n",
    "        - Method: Controls the expected proportion of false positives.\n",
    "        - Best for: Large-scale multiple testing, such as in genomics or neuroimaging.\n",
    "    - b. __Benjamini-Yekutieli Procedure__\n",
    "        - Use case: A more conservative version of Benjamini-Hochberg.\n",
    "        - Method: Accounts for certain types of positive dependence between tests.\n",
    "        - Best for: When you suspect positive correlations between your tests.\n",
    "- __Dunnett's Test__\n",
    "    - Use case: When comparing multiple treatments to a single control group.\n",
    "    - Method: Adjusts for multiple comparisons while maintaining higher power than Bonferroni.\n",
    "    - Best for: Experiments with a control group and multiple treatment groups.\n",
    "- __Tukey's Honest Significant Difference (HSD)__\n",
    "    - Use case: For all pairwise comparisons after an ANOVA.\n",
    "    - Method: Adjusts for multiple comparisons in a way that's less conservative than Bonferroni.\n",
    "    - Best for: Post-hoc analysis following a significant ANOVA result.\n",
    "\n",
    "***\n",
    "\n",
    "__General guidelines for corrections:__\n",
    "\n",
    "- Use Bonferroni or Holm-Bonferroni for a small number of planned comparisons where controlling Type I error is crucial.\n",
    "\n",
    "- Use FDR methods for large-scale multiple testing where some false positives are acceptable.\n",
    "\n",
    "- Use Tukey's HSD or Dunnett's Test for post-hoc analysis after ANOVA, depending on your comparison needs.\n",
    "\n",
    "- Consider the trade-off between Type I error control and statistical power when choosing a correction method.\n",
    "\n",
    "__In the context of military and intelligence data analysis, the choice of correction method might depend on the specific scenario:__\n",
    "\n",
    "- For critical decision-making with a small number of comparisons, use conservative methods like Bonferroni.\n",
    "\n",
    "- For large-scale data analysis (e.g., signal processing, pattern recognition in big data), consider FDR methods.\n",
    "\n",
    "- For comparing multiple military strategies or technologies against a standard, Dunnett's Test might be appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0801f5-dfb9-403a-a388-168cd86ba77f",
   "metadata": {},
   "source": [
    "__Parametric tests and their non-parametric alternatives:__\n",
    "\n",
    "- [Independent Samples t-test](#Independent-Samples-t-test) >>> [Mann-Whitney U Test](#Mann-Whitney-U-Test)\n",
    "\n",
    "- [Paired Samples t-test](#Paired-Samples-t-test) >>> [Wilcoxon Signed-Rank Test](#Wilcoxon-Signed-Rank-Test)\n",
    "\n",
    "- [One-sample t-test](#One-sample-t-test) >>> [Wilcoxon Signed-Rank Test (against a known median)](#Wilcoxon-Signed-Rank-Test)\n",
    "\n",
    "- [Welch's t-test (unequal variances t-test)](#Welch's-t-test-(unequal-variances-t-test)) >>> [Mann-Whitney U Test](#Mann-Whitney-U-Test)\n",
    "\n",
    "- [ANOVA (Analysis of Variance)](#ANOVA-(Analysis-of-Variance)) >>> [Kruskal-Wallis H-Test](#Kruskal-Wallis-H-Test)\n",
    "\n",
    "- [Repeated Measures ANOVA](#Repeated-Measures-ANOVA) >>> [Friedman Test](#Friedman-Test)\n",
    "\n",
    "- [Pearson Correlation Test](#Pearson-Correlation-Test) >>> [Spearman Rank Correlation](#Spearman-Rank-Correlation) or [Kendall's Tau](#Kendall's-Tau)\n",
    "\n",
    "- [F-Test](#F-Test) >>> [Levene's Test (for equality of variances)](#Levene's-Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873e7b9c-334d-4c02-9cbe-5f2b58ed168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adebede-8bc1-4a13-b867-0728ffd488a9",
   "metadata": {},
   "source": [
    "# Independent Samples t-test\n",
    "\n",
    "    Requirements:\n",
    "        - Two independent groups\n",
    "        - Continuous dependent variable\n",
    "        - Approximately normally distributed data in each group\n",
    "        - Homogeneity of variances\n",
    "        - Random sampling or assignment\n",
    "\n",
    "__Use case__: Comparing the effectiveness of two different drone models in target identification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa09e5b-b541-4ab3-8092-6de8f2f7ff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independent t-test: t-statistic = 2.8252, p-value = 0.0153\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "drone_model_a = np.array([0.82, 0.85, 0.88, 0.90, 0.86, 0.87, 0.89])\n",
    "drone_model_b = np.array([0.79, 0.81, 0.85, 0.84, 0.82, 0.83, 0.86])\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(drone_model_a, drone_model_b)\n",
    "print(f\"Independent t-test: t-statistic = {t_stat:.4f}, p-value = {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a0567e-cd4d-4d9f-8154-ebabcf34c6e3",
   "metadata": {},
   "source": [
    "## Bonferroni Correction\n",
    "\n",
    "    Requirements:\n",
    "        - Multiple comparisons or hypothesis tests\n",
    "        - Desire to control family-wise error rate\n",
    "\n",
    "__Use case__: Adjusting p-values when comparing multiple pairs of military units' performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07b64697-9dc5-4c94-9a76-1f6dd2375e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original p-value 1: 0.2218\n",
      "Bonferroni corrected p-value 1: 0.6654\n",
      "Original p-value 2: 0.1855\n",
      "Bonferroni corrected p-value 2: 0.5565\n",
      "Original p-value 3: 0.6745\n",
      "Bonferroni corrected p-value 3: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Simulated data for three units\n",
    "unit1 = np.random.normal(100, 15, 30)\n",
    "unit2 = np.random.normal(105, 15, 30)\n",
    "unit3 = np.random.normal(110, 15, 30)\n",
    "\n",
    "# Perform multiple t-tests\n",
    "_, p12 = stats.ttest_ind(unit1, unit2)\n",
    "_, p13 = stats.ttest_ind(unit1, unit3)\n",
    "_, p23 = stats.ttest_ind(unit2, unit3)\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "p_values = [p12, p13, p23]\n",
    "n_tests = len(p_values)\n",
    "alpha = 0.05\n",
    "\n",
    "for i, p in enumerate(p_values, 1):\n",
    "    print(f\"Original p-value {i}: {p:.4f}\")\n",
    "    print(f\"Bonferroni corrected p-value {i}: {min(p * n_tests, 1):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f651344-f1be-4f4d-b7b3-2d3e0c8b14a0",
   "metadata": {},
   "source": [
    "# Paired Samples t-test\n",
    "\n",
    "    Requirements:\n",
    "        - Paired observations\n",
    "        - Continuous dependent variable\n",
    "        - Differences between pairs are normally distributed\n",
    "        - Random sampling or assignment\n",
    "\n",
    "__Use case__: Evaluating soldier performance in urban combat scenarios before and after implementing a new AI-assisted decision-making system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a55438c8-2e1b-46bf-bae2-8556ce0c51d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired t-test: t-statistic = -13.0000, p-value = 0.0000\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "performance_before = np.array([72, 75, 68, 80, 76, 79, 81])\n",
    "performance_after = np.array([78, 82, 75, 85, 80, 84, 86])\n",
    "\n",
    "t_stat, p_value = stats.ttest_rel(performance_before, performance_after)\n",
    "print(f\"Paired t-test: t-statistic = {t_stat:.4f}, p-value = {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08b28d8-7cbc-4c37-808d-e5442888e923",
   "metadata": {},
   "source": [
    "# One-sample t-test\n",
    "\n",
    "    Requirements:\n",
    "        - One group\n",
    "        - Continuous dependent variable\n",
    "        - Approximately normally distributed data\n",
    "        - Random sampling\n",
    "\n",
    "__Use case__: Determining if the average response time of a new automated missile defense system differs significantly from the required standard of 2.5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b2de4c8-f467-4af3-bc51-4be715386bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-sample t-test: t-statistic = -0.4781, p-value = 0.6454\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "response_times = np.array([2.3, 2.4, 2.6, 2.5, 2.4, 2.7, 2.5, 2.3, 2.6])\n",
    "standard_time = 2.5\n",
    "\n",
    "t_stat, p_value = stats.ttest_1samp(response_times, standard_time)\n",
    "print(f\"One-sample t-test: t-statistic = {t_stat:.4f}, p-value = {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92ae2b-55e7-4aab-9b03-618f147e2b20",
   "metadata": {},
   "source": [
    "# Welch's t-test (unequal variances t-test)\n",
    "    Requirements:\n",
    "        - Two independent groups\n",
    "        - Continuous dependent variable\n",
    "        - Approximately normally distributed data in each group\n",
    "        - Does not assume equal variances\n",
    "        - Random sampling or assignment\n",
    "\n",
    "__Use case__: Comparing the effective range of two different electronic warfare systems, where the variability in performance is expected to differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5abc7932-fdfe-4e59-bb40-f6ebbe5b5397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welch's t-test: t-statistic = 2.4926, p-value = 0.0287\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "system_a_range = np.array([120, 125, 118, 122, 127, 123])\n",
    "system_b_range = np.array([115, 120, 110, 118, 122, 117, 121, 119])\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(system_a_range, system_b_range, equal_var=False)\n",
    "print(f\"Welch's t-test: t-statistic = {t_stat:.4f}, p-value = {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56342d46-c57f-4876-9f60-0fb58d2233b8",
   "metadata": {},
   "source": [
    "# Two-tailed vs One-tailed t-test\n",
    "\n",
    "    Requirements:\n",
    "        - Decision on directionality of the hypothesis\n",
    "        - Two independent groups\n",
    "        - Continuous dependent variable\n",
    "        - Approximately normally distributed data in each group\n",
    "        - Homogeneity of variances\n",
    "        - Random sampling or assignment\n",
    "\n",
    "__Use case__: Assessing if a new camouflage technology significantly improves or reduces detection time compared to the current standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c56f4e2-210f-471f-bee2-6aff8820add9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-tailed t-test: t-statistic = -4.3818, p-value = 0.0009\n",
      "One-tailed t-test: t-statistic = -4.3818, p-value = 0.0004\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "new_camo_detection = np.array([3.2, 2.8, 3.1, 2.9, 3.0, 3.3, 2.7])\n",
    "old_camo_detection = np.array([3.5, 3.3, 3.4, 3.6, 3.2, 3.7, 3.5])\n",
    "\n",
    "# Two-tailed test (is there any difference?)\n",
    "t_stat, p_value_two = stats.ttest_ind(new_camo_detection, old_camo_detection)\n",
    "print(f\"Two-tailed t-test: t-statistic = {t_stat:.4f}, p-value = {p_value_two:.4f}\")\n",
    "\n",
    "# One-tailed test (is new camouflage better?)\n",
    "p_value_one = p_value_two / 2  # For a one-tailed test, divide two-tailed p-value by 2\n",
    "print(f\"One-tailed t-test: t-statistic = {t_stat:.4f}, p-value = {p_value_one:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9647b74-b16f-4e24-9a62-456a28ef663f",
   "metadata": {},
   "source": [
    "# ANOVA (Analysis of Variance)\n",
    "\n",
    "    Requirements:\n",
    "       - Continuous dependent variable\n",
    "       - Categorical independent variable with two or more groups\n",
    "       - Independence of observations\n",
    "       - Normal distribution of residuals\n",
    "       - Homogeneity of variances across groups\n",
    "       - Random sampling\n",
    "\n",
    "__Use case__: Comparing performance of multiple units in a field exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d949aa6b-2976-461d-a5c5-c0c91ab61bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-way ANOVA: F-statistic = 39.303703703703746, p-value = 5.3964139070098445e-06\n",
      "              sum_sq    df          F    PR(>F)\n",
      "C(unit)   353.733333   2.0  39.303704  0.000005\n",
      "Residual   54.000000  12.0        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "\n",
    "unit_a = [85, 88, 90, 87, 92]\n",
    "unit_b = [79, 82, 81, 80, 84]\n",
    "unit_c = [91, 94, 93, 92, 95]\n",
    "\n",
    "f_stat, p_value = stats.f_oneway(unit_a, unit_b, unit_c)\n",
    "print(f\"One-way ANOVA: F-statistic = {f_stat}, p-value = {p_value}\")\n",
    "\n",
    "# Using statsmodels for more detailed output\n",
    "data = pd.DataFrame({\n",
    "    'performance': unit_a + unit_b + unit_c,\n",
    "    'unit': ['A']*5 + ['B']*5 + ['C']*5\n",
    "})\n",
    "model = ols('performance ~ C(unit)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127c4d5-e011-4719-919e-a599ce1632f3",
   "metadata": {},
   "source": [
    "# Friedman Test\n",
    "\n",
    "    Requirements:\n",
    "        - Three or more groups of related samples\n",
    "        - Ordinal or continuous data\n",
    "        - Does not assume normal distribution\n",
    "\n",
    "__Use case__: Comparing the effectiveness of different combat strategies across multiple scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19bbde4f-6ea6-49b8-8ab0-67460f2375f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman test statistic: 3.600\n",
      "P-value: 0.165\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "strategy_a = np.array([7, 8, 6, 9, 8])\n",
    "strategy_b = np.array([6, 7, 8, 5, 7])\n",
    "strategy_c = np.array([8, 9, 7, 8, 9])\n",
    "\n",
    "statistic, p_value = stats.friedmanchisquare(strategy_a, strategy_b, strategy_c)\n",
    "print(f\"Friedman test statistic: {statistic:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209a657-ecf4-48e6-ac0c-db95fe5b1377",
   "metadata": {},
   "source": [
    "# MANOVA (Multivariate Analysis of Variance)\n",
    "\n",
    "    Requirements:\n",
    "        - One or more categorical independent variables\n",
    "        - Two or more continuous dependent variables\n",
    "        - Independence of observations\n",
    "        - Multivariate normality\n",
    "        - Homogeneity of variance-covariance matrices\n",
    "        - No multicollinearity\n",
    "\n",
    "__Use case__: Analyzing the effects of different training programs on multiple performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a69d614-838e-40f5-bb06-1afbb6620c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>r</th>\n",
       "      <th>CI95%</th>\n",
       "      <th>p-val</th>\n",
       "      <th>BF10</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pearson</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>2.736911e-47</td>\n",
       "      <td>4.733e+30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n    r       CI95%         p-val       BF10  power\n",
       "pearson  8  1.0  [1.0, 1.0]  2.736911e-47  4.733e+30    1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Simulated data for three groups and two dependent variables\n",
    "group1 = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "group2 = np.array([[2, 3], [4, 5], [6, 7], [8, 9]])\n",
    "group3 = np.array([[3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "\n",
    "# F, p = stats.manova(np.array([group1, group2, group3]))\n",
    "# print(f\"MANOVA F-statistic: {F}\")\n",
    "# print(f\"p-value: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487f252e-982a-4ee9-bfff-57a4c9a2dacd",
   "metadata": {},
   "source": [
    "# ANCOVA (Analysis of Covariance)\n",
    "\n",
    "    Requirements:\n",
    "        - One categorical independent variable\n",
    "        - One continuous dependent variable\n",
    "        - One or more continuous covariates\n",
    "        - Linear relationship between covariate and dependent variable\n",
    "        - Homogeneity of regression slopes\n",
    "        - Independence of covariate and treatment effect\n",
    "    \n",
    "__Use case__: Evaluating the effect of different combat training methods on performance, while controlling for years of experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7cd25-5b40-4133-b31b-68202d683ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Simulated data\n",
    "data = {\n",
    "    'performance': [75, 82, 78, 85, 90, 88, 92, 95, 89, 91],\n",
    "    'training_method': ['A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B'],\n",
    "    'years_experience': [2, 3, 2, 4, 5, 3, 4, 5, 4, 6]\n",
    "}\n",
    "\n",
    "model = ols('performance ~ C(training_method) + years_experience', data=data).fit()\n",
    "ancova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(ancova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d9458-be3e-4ee1-8215-398c558a7211",
   "metadata": {},
   "source": [
    "# Repeated Measures ANOVA\n",
    "\n",
    "    Requirements:\n",
    "        - One categorical independent variable (within-subjects factor)\n",
    "        - One continuous dependent variable\n",
    "        - Sphericity (equal variances of the differences between all pairs of groups)\n",
    "        - No significant outliers\n",
    "        - Dependent variable should be approximately normally distributed\n",
    "\n",
    "__Use case__: Analyzing soldier performance across multiple time points during a training program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157411a6-49e8-4409-9a84-45dd9041e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Simulated data\n",
    "data = pd.DataFrame({\n",
    "    'Soldier': np.repeat(range(1, 11), 3),\n",
    "    'Time': np.tile(['Week1', 'Week2', 'Week3'], 10),\n",
    "    'Performance': np.random.normal(70, 10, 30)\n",
    "})\n",
    "\n",
    "# Reshape data for repeated measures ANOVA\n",
    "wide_data = data.pivot(index='Soldier', columns='Time', values='Performance')\n",
    "\n",
    "F, p = stats.f_oneway(wide_data['Week1'], wide_data['Week2'], wide_data['Week3'])\n",
    "print(f\"Repeated Measures ANOVA F-statistic: {F:.4f}\")\n",
    "print(f\"p-value: {p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45536d7-4e71-4a72-891b-2e18d2bce624",
   "metadata": {},
   "source": [
    "# Hotelling's T-squared Test\n",
    "\n",
    "    Requirements:\n",
    "        - Two groups of multivariate data\n",
    "        - Equal sample sizes for both groups\n",
    "        - Multivariate normality\n",
    "        - Homogeneity of covariance matrices\n",
    "\n",
    "__Use case__: Comparing two military units across multiple performance metrics simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b3d8c1-72b7-4c61-bccf-31fdf43e3b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Simulated data for two units, each with two performance metrics\n",
    "unit1 = np.random.multivariate_normal([100, 80], [[100, 0], [0, 64]], 30)\n",
    "unit2 = np.random.multivariate_normal([105, 85], [[100, 0], [0, 64]], 30)\n",
    "\n",
    "t2, p = stats.hotelling_t2(unit1, unit2)\n",
    "print(f\"Hotelling's T-squared statistic: {t2:.4f}\")\n",
    "print(f\"p-value: {p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc64188f-bf37-427f-9a1e-8d8622f5d4a9",
   "metadata": {},
   "source": [
    "# Chi-Square Test of Independence\n",
    "\n",
    "    Requirements:\n",
    "       - Categorical variables\n",
    "       - Expected frequencies in each cell should be at least 5\n",
    "       - Independence of observations\n",
    "       - Random sampling\n",
    "\n",
    "__Use case__: Analyzing the relationship between types of security incidents and locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c1d5eea-a3f6-44a2-a04b-21f88932110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic = 2.205104669887279, p-value = 0.6980948266695272\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Contingency table: rows are incident types, columns are locations\n",
    "contingency_table = np.array([\n",
    "    [10, 5, 8],   # Type A incidents\n",
    "    [15, 12, 7],  # Type B incidents\n",
    "    [20, 15, 10]  # Type C incidents\n",
    "])\n",
    "\n",
    "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "print(f\"Chi-square statistic = {chi2}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a0c15f-79de-42b9-a29b-8a7570bd0b6e",
   "metadata": {},
   "source": [
    "# Kolmogorov-Smirnov Test\n",
    "    \n",
    "    Requirements:\n",
    "       - Continuous data\n",
    "       - For two-sample test: independent samples\n",
    "       - For one-sample test: fully specified theoretical distribution\n",
    "\n",
    "__Use case__: Comparing the distribution of enemy movement patterns to a theoretical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ba3d47-dd44-4900-9ee5-0c966580b331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS test statistic = 0.10318376480352165, p-value = 0.22162534200209028\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "observed_movements = np.random.normal(loc=50, scale=10, size=100)\n",
    "theoretical_distribution = stats.norm(loc=50, scale=10)\n",
    "\n",
    "ks_statistic, p_value = stats.kstest(observed_movements, theoretical_distribution.cdf)\n",
    "print(f\"KS test statistic = {ks_statistic}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b789c9c-1f6a-4c3a-998d-2ab03220f0ba",
   "metadata": {},
   "source": [
    "# Mann-Whitney U Test\n",
    "\n",
    "    Requirements:\n",
    "       - Ordinal or continuous dependent variable\n",
    "       - Categorical independent variable with two groups\n",
    "       - Independence of observations\n",
    "       - Similar shape of distributions in both groups (if comparing medians)\n",
    "\n",
    "__Use case__: Comparing effectiveness of two different camouflage techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a45b0b-8f2f-4fab-a625-de5ba2fe7d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U statistic = 4.0, p-value = 0.010432890182919985\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "technique_a = [12, 15, 10, 18, 20, 14, 16]  # detection time in seconds\n",
    "technique_b = [18, 22, 17, 25, 23, 20, 21]\n",
    "\n",
    "statistic, p_value = stats.mannwhitneyu(technique_a, technique_b)\n",
    "print(f\"Mann-Whitney U statistic = {statistic}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5460ec74-7446-45ae-9004-3667fd2d83be",
   "metadata": {},
   "source": [
    "# Wilcoxon Signed-Rank Test\n",
    "    \n",
    "    Requirements:\n",
    "       - Paired observations\n",
    "       - Ordinal or continuous dependent variable\n",
    "       - Symmetrical distribution of differences between pairs\n",
    "\n",
    "__Use case__: Comparing mission success rates before and after a new tactical training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec97f9b2-a17c-4799-a084-3f573b1552a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon signed-rank test statistic = 0.0, p-value = 0.015625\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "before_training = [0.7, 0.65, 0.8, 0.75, 0.72, 0.68, 0.77]\n",
    "after_training = [0.8, 0.75, 0.85, 0.82, 0.79, 0.76, 0.83]\n",
    "\n",
    "statistic, p_value = stats.wilcoxon(before_training, after_training)\n",
    "print(f\"Wilcoxon signed-rank test statistic = {statistic}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b920c573-d777-430e-bdb3-a0a792d163bd",
   "metadata": {},
   "source": [
    "# Shapiro-Wilk Test\n",
    "    \n",
    "    Requirements:\n",
    "       - Continuous data\n",
    "       - Sample size between 3 and 5000\n",
    "\n",
    "__Use case__: Testing if the distribution of mission durations is normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c087eb0a-c029-485f-9a76-f08c2aee827a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk test statistic = 0.9689416723658181, p-value = 0.8808628454457482\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "mission_durations = [120, 135, 110, 140, 125, 130, 115, 145, 120, 135]\n",
    "\n",
    "statistic, p_value = stats.shapiro(mission_durations)\n",
    "print(f\"Shapiro-Wilk test statistic = {statistic}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f70b1b-adce-46b8-8049-70efc6360f8b",
   "metadata": {},
   "source": [
    "# F-Test\n",
    "    \n",
    "    Requirements:\n",
    "       - Continuous dependent variable\n",
    "       - Normally distributed data in each group\n",
    "       - Independent observations\n",
    "\n",
    "__Use case__: Comparing the variability in accuracy between two different weapon systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac906c8-0237-4f6f-86f4-bf0c9064099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-test statistic = 0.999999999999996, p-value = 0.5000000000000021\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "system_a = np.array([0.95, 0.92, 0.98, 0.94, 0.96, 0.93, 0.97])\n",
    "system_b = np.array([0.88, 0.91, 0.85, 0.89, 0.87, 0.90, 0.86])\n",
    "\n",
    "f_statistic = np.var(system_a, ddof=1) / np.var(system_b, ddof=1)\n",
    "df1, df2 = len(system_a) - 1, len(system_b) - 1\n",
    "p_value = 1 - stats.f.cdf(f_statistic, df1, df2)\n",
    "\n",
    "print(f\"F-test statistic = {f_statistic}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2e860e-c80b-4786-beef-feaa5c8a6527",
   "metadata": {},
   "source": [
    "# Z-Test\n",
    "    \n",
    "    Requirements:\n",
    "       - Large sample size (n > 30)\n",
    "       - Known population standard deviation\n",
    "       - Normally distributed population (or large sample size)\n",
    "\n",
    "__Use case__: Testing if the proportion of successful missions meets a target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b031bf-65d4-4e50-b2ed-314e4db2496d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-test statistic = -1.0050378152592119, p-value = 0.31487864133641996\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.stats.proportion as proportions\n",
    "\n",
    "successes = 45\n",
    "total_missions = 100\n",
    "target_proportion = 0.5\n",
    "\n",
    "z_statistic, p_value = proportions.proportions_ztest(count=successes, nobs=total_missions, value=target_proportion)\n",
    "print(f\"Z-test statistic = {z_statistic}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8302da-55cf-4c95-b5de-f495899f3f00",
   "metadata": {},
   "source": [
    "# Kruskal-Wallis H-Test\n",
    "    \n",
    "    Requirements:\n",
    "        - Ordinal or continuous dependent variable\n",
    "        - Categorical independent variable with two or more groups\n",
    "        - Independence of observations\n",
    "        - Similar shape of distributions across groups\n",
    "\n",
    "__Use case__: Comparing effectiveness of multiple communication protocols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1541d33-663f-4364-a118-502723363256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis H-test statistic = 11.816100178890885, p-value = 0.0027174805686494947\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "protocol_a = [85, 88, 90, 87, 92]\n",
    "protocol_b = [79, 82, 81, 80, 84]\n",
    "protocol_c = [91, 94, 93, 92, 95]\n",
    "\n",
    "h_statistic, p_value = stats.kruskal(protocol_a, protocol_b, protocol_c)\n",
    "print(f\"Kruskal-Wallis H-test statistic = {h_statistic}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cefc7f-cc1a-4917-9374-0f13767d682b",
   "metadata": {},
   "source": [
    "# Pearson Correlation Test\n",
    "    \n",
    "    Requirements:\n",
    "        - Two continuous variables\n",
    "        - Linear relationship between variables\n",
    "        - No significant outliers\n",
    "        - Normally distributed variables (for inferential statistics)\n",
    "\n",
    "__Use case__: Testing for linear correlation between patrol frequency and incident occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e09f87a-a5d7-497d-b321-6082c66138ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient = -0.9922858194799438, p-value = 9.997264988456582e-06\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "patrol_frequency = [2, 3, 4, 5, 6, 7, 8]\n",
    "incident_count = [10, 8, 7, 6, 5, 4, 3]\n",
    "\n",
    "correlation, p_value = stats.pearsonr(patrol_frequency, incident_count)\n",
    "print(f\"Pearson correlation coefficient = {correlation}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb383d6-52a3-42be-994d-af3d5d71f23e",
   "metadata": {},
   "source": [
    "# Spearman Rank Correlation\n",
    "    \n",
    "    Requirements:\n",
    "        - Two variables that are ordinal, interval, or ratio\n",
    "        - Monotonic relationship between variables (not necessarily linear)\n",
    "        - Does not assume normal distribution\n",
    "\n",
    "__Use case__: Assessing the relationship between military rank and leadership effectiveness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee7ee70e-2ac4-4503-bdb0-b1855c8dd735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman rank correlation coefficient = 1.0, p-value = 0.0\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "rank = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "leadership_score = np.array([7, 8, 6, 9, 10, 7, 8, 9, 8, 10])\n",
    "\n",
    "correlation, p_value = stats.spearmanr(rank, leadership_score)\n",
    "print(f\"Spearman correlation: {correlation:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610dcc5-16d8-492d-b882-6e2963d33fa8",
   "metadata": {},
   "source": [
    "# Granger Causality Test\n",
    "    \n",
    "    Requirements:\n",
    "        - Time series data\n",
    "        - Stationary time series\n",
    "        - Sufficient number of observations (typically > 30)\n",
    "\n",
    "__Use case__: Testing if changes in enemy movement patterns can predict future engagement frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec4eb11f-3acf-431c-9f82-935660ad8c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.7730  , p=0.3815  , df_denom=96, df_num=1\n",
      "ssr based chi2 test:   chi2=0.7971  , p=0.3720  , df=1\n",
      "likelihood ratio test: chi2=0.7939  , p=0.3729  , df=1\n",
      "parameter F test:         F=0.7730  , p=0.3815  , df_denom=96, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=4.1012  , p=0.0196  , df_denom=93, df_num=2\n",
      "ssr based chi2 test:   chi2=8.6434  , p=0.0133  , df=2\n",
      "likelihood ratio test: chi2=8.2833  , p=0.0159  , df=2\n",
      "parameter F test:         F=4.1012  , p=0.0196  , df_denom=93, df_num=2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "np.random.seed(1)\n",
    "enemy_movements = np.random.normal(0, 1, 100)\n",
    "engagements = np.roll(enemy_movements, 1) + np.random.normal(0, 0.5, 100)\n",
    "\n",
    "data = pd.DataFrame({'movements': enemy_movements, 'engagements': engagements})\n",
    "granger_test = grangercausalitytests(data[['movements', 'engagements']], maxlag=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78766877-4aea-4393-a19e-d2c2fa36f54c",
   "metadata": {},
   "source": [
    "# Durbin-Watson Test\n",
    "    \n",
    "    Requirements:\n",
    "        - Residuals from a linear regression model\n",
    "        - Time series or ordered data\n",
    "\n",
    "__Use case__: Testing for autocorrelation in the residuals of a regression analysis of factors influencing mission success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1de01f0a-69c2-40fd-a3be-d23af2658541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durbin-Watson statistic = 2.203879412891881\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# Assuming you've performed a regression and have the residuals\n",
    "residuals = np.random.normal(0, 1, 100)  # Replace with actual residuals\n",
    "\n",
    "dw_statistic = durbin_watson(residuals)\n",
    "print(f\"Durbin-Watson statistic = {dw_statistic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ed7e8b-3cbd-431a-8316-8d120de22a57",
   "metadata": {},
   "source": [
    "# Augmented Dickey-Fuller Test\n",
    "    \n",
    "    Requirements:\n",
    "        - Time series data\n",
    "        - Sufficient number of observations (typically > 50)\n",
    "\n",
    "__Use case__: Testing for stationarity in a time series of daily security incident counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bac6e042-f594-49c4-948f-6dbf87d421e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -1.5626438117096204\n",
      "p-value: 0.502326582629831\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "import numpy as np\n",
    "\n",
    "# Generate a non-stationary time series\n",
    "incident_counts = np.cumsum(np.random.normal(0, 1, 100)) + 50\n",
    "\n",
    "result = adfuller(incident_counts)\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef267ff3-8990-4b51-bd58-93e14ce64b99",
   "metadata": {},
   "source": [
    "# Levene's Test\n",
    "\n",
    "    Requirements:\n",
    "        - Two or more groups of continuous data\n",
    "        - Samples are independent\n",
    "        - Does not assume normal distribution\n",
    "\n",
    "__Use case__: Checking if different military units have equal variances in their performance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e607d9a-2bf7-43f6-af0a-1fdeb9221a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "unit_a = np.array([75, 80, 85, 90, 95])\n",
    "unit_b = np.array([70, 75, 80, 85, 90])\n",
    "unit_c = np.array([80, 85, 90, 95, 100])\n",
    "\n",
    "statistic, p_value = stats.levene(unit_a, unit_b, unit_c)\n",
    "print(f\"Levene's test statistic: {statistic:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47b9cd-3dd2-4352-81c3-225c6701e27e",
   "metadata": {},
   "source": [
    "# McNemar's Test\n",
    "\n",
    "    Requirements:\n",
    "        - Paired nominal data\n",
    "        - Dichotomous variables (two possible outcomes)\n",
    "        - Large sample size (>25)\n",
    "\n",
    "__Use case__: Evaluating the effectiveness of a new training program on soldiers' pass/fail rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b661d22-343c-4c9b-b2cf-2e40c60f417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Contingency table: [before_fail, before_pass], [after_fail, after_pass]\n",
    "contingency_table = np.array([[30, 50], [10, 110]])\n",
    "\n",
    "statistic, p_value = stats.mcnemar(contingency_table, exact=False, correction=True)\n",
    "print(f\"McNemar's test statistic: {statistic:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c530045-88f5-4f07-ac46-fb4ef2d3139d",
   "metadata": {},
   "source": [
    "# Kendall's Tau\n",
    "\n",
    "    Requirements:\n",
    "        - Two ordinal variables\n",
    "        - Measures strength and direction of ordinal association\n",
    "        - Does not assume normal distribution\n",
    "\n",
    "__Use case__: Analyzing the relationship between years of service and mission success rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92156a5-6286-4fc2-a1bb-247e2545d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "years_of_service = np.array([1, 3, 4, 6, 7, 8, 9, 11, 12, 14])\n",
    "mission_success = np.array([0.6, 0.7, 0.6, 0.8, 0.8, 0.9, 0.9, 0.8, 0.9, 1.0])\n",
    "\n",
    "tau, p_value = stats.kendalltau(years_of_service, mission_success)\n",
    "print(f\"Kendall's tau: {tau:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
