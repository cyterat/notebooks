{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6566e16d-0cb6-44ea-8acf-815882f13c5e",
   "metadata": {},
   "source": [
    "<span style=\"color:#333333; font-size:24px; font-weight:bold\"> Compiled by <a href=https://github.com/cyterat style=\"color:#00b2b7;\">cyterat</a></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51126520-94c5-4524-b3d7-1cb3b7975bee",
   "metadata": {},
   "source": [
    "# Explanation:\n",
    "\n",
    "- __confidence_level__ is typically 0.95 for 95% confidence\n",
    "\n",
    "- __margin_error__ is the acceptable error margin (e.g., 0.05 for Â±5%)\n",
    "\n",
    "- __std_dev__ is the estimated standard deviation of the population\n",
    "\n",
    "- __p__ is the estimated proportion (0.5 is used when unknown, as it gives the largest sample size)\n",
    "\n",
    "- __power__ is typically set to 0.8, meaning an 80% chance of detecting an effect if one exists\n",
    "\n",
    "- __alpha__ is the significance level, typically 0.05\n",
    "\n",
    "- __r__ is the expected correlation coefficient\n",
    "\n",
    "- __deff__ is the design effect for cluster sampling, typically between 1 and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48f0efb-5303-4442-888b-afb216dd9c55",
   "metadata": {},
   "source": [
    "# 1. Sample Size for Estimating a Proportion\n",
    "\n",
    "__Use case__: When you're trying to estimate the prevalence of a certain characteristic in a population (e.g., the proportion of successful missions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dab391-c170-42d3-909e-0497e6ded39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sample_size_proportion(confidence_level, margin_error, p=0.5):\n",
    "    z_score = {\n",
    "        0.90: 1.645,\n",
    "        0.95: 1.96,\n",
    "        0.99: 2.576\n",
    "    }.get(confidence_level, 1.96)\n",
    "    \n",
    "    sample_size = (z_score**2 * p * (1-p)) / (margin_error**2)\n",
    "    return math.ceil(sample_size)\n",
    "\n",
    "# Example usage\n",
    "n = sample_size_proportion(confidence_level=0.95, margin_error=0.05)\n",
    "print(f\"Required sample size: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d40f664-728c-486d-9f88-b6275271d5d5",
   "metadata": {},
   "source": [
    "# 2. Sample Size for Comparing Two Proportions\n",
    "\n",
    "__Use case__: When you're comparing the effectiveness of two different strategies or systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e2ac7-9b41-45c7-85eb-74adbe175d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "def sample_size_two_proportions(p1, p2, power=0.8, alpha=0.05):\n",
    "    z_alpha = stats.norm.ppf(1 - alpha/2)\n",
    "    z_beta = stats.norm.ppf(power)\n",
    "    \n",
    "    p_pooled = (p1 + p2) / 2\n",
    "    q_pooled = 1 - p_pooled\n",
    "    \n",
    "    n = ((z_alpha * math.sqrt(2 * p_pooled * q_pooled) + \n",
    "          z_beta * math.sqrt(p1 * (1-p1) + p2 * (1-p2)))**2) / (p1 - p2)**2\n",
    "    \n",
    "    return math.ceil(n)\n",
    "\n",
    "# Example usage\n",
    "n = sample_size_two_proportions(p1=0.3, p2=0.4, power=0.8, alpha=0.05)\n",
    "print(f\"Required sample size per group: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8198d37a-3aaf-4900-81e5-d7eb8871f09c",
   "metadata": {},
   "source": [
    "# 3. Sample Size for Estimating a Mean\n",
    "\n",
    "__Use case__: When you're trying to estimate an average value in a population (e.g., average mission duration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c3d8f-8932-4702-8d19-be2b36ee799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sample_size_mean(confidence_level, margin_error, std_dev):\n",
    "    z_score = {\n",
    "        0.90: 1.645,\n",
    "        0.95: 1.96,\n",
    "        0.99: 2.576\n",
    "    }.get(confidence_level, 1.96)\n",
    "    \n",
    "    sample_size = (z_score * std_dev / margin_error)**2\n",
    "    return math.ceil(sample_size)\n",
    "\n",
    "# Example usage\n",
    "n = sample_size_mean(confidence_level=0.95, margin_error=0.5, std_dev=2.5)\n",
    "print(f\"Required sample size: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964810fc-c243-4313-bddc-f33b3bb66717",
   "metadata": {},
   "source": [
    "# 4. Sample Size for Detecting a Correlation\n",
    "\n",
    "__Use case__: When you're trying to detect a relationship between two continuous variables (e.g., training hours and performance scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50837559-04cd-4555-8cb0-07cf6ebc26bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "def sample_size_correlation(r, alpha=0.05, power=0.8):\n",
    "    z_alpha = stats.norm.ppf(1 - alpha/2)\n",
    "    z_beta = stats.norm.ppf(power)\n",
    "    \n",
    "    n = ((z_alpha + z_beta) / (0.5 * math.log((1+r)/(1-r))))**2 + 3\n",
    "    \n",
    "    return math.ceil(n)\n",
    "\n",
    "# Example usage\n",
    "n = sample_size_correlation(r=0.3, alpha=0.05, power=0.8)\n",
    "print(f\"Required sample size: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed19338-2d27-43dd-adf4-7b599e7f644a",
   "metadata": {},
   "source": [
    "# 5. Sample Size for Time Series Analysis\n",
    "\n",
    "__Info__: For time series analysis, the sample size often refers to the number of time points. A general rule of thumb is to have at least 50 observations for basic time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2355d7b7-bfa4-41a6-a25b-84c2818c2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_size_time_series(frequency='daily', duration_years=1):\n",
    "    frequencies = {\n",
    "        'daily': 365,\n",
    "        'weekly': 52,\n",
    "        'monthly': 12,\n",
    "        'quarterly': 4\n",
    "    }\n",
    "    \n",
    "    n = frequencies.get(frequency, 365) * duration_years\n",
    "    return max(n, 50)  # Ensure at least 50 observations\n",
    "\n",
    "# Example usage\n",
    "n = sample_size_time_series(frequency='weekly', duration_years=2)\n",
    "print(f\"Required number of time points: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea0c31e-1192-4d69-81c9-fb8f33404345",
   "metadata": {},
   "source": [
    "# 6. Sample Size for Time Series Analysis\n",
    "\n",
    "__Info__: For time series analysis, the sample size often refers to the number of time points. A general rule of thumb is to have at least 50 observations for basic time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561c189-f883-48b1-9b6b-b443b5365a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sample_size_cluster(confidence_level, margin_error, p=0.5, deff=2):\n",
    "    z_score = {\n",
    "        0.90: 1.645,\n",
    "        0.95: 1.96,\n",
    "        0.99: 2.576\n",
    "    }.get(confidence_level, 1.96)\n",
    "    \n",
    "    sample_size = ((z_score**2 * p * (1-p)) / (margin_error**2)) * deff\n",
    "    return math.ceil(sample_size)\n",
    "\n",
    "# Example usage\n",
    "n = sample_size_cluster(confidence_level=0.95, margin_error=0.05, deff=2)\n",
    "print(f\"Required sample size: {n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
