{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f3668c-3e63-4cc8-84ef-4feb8e1f87ec",
   "metadata": {},
   "source": [
    "<span style=\"color:#333333; font-size:24px; font-weight:bold\"> Compiled by <a href=https://github.com/cyterat style=\"color:#00b2b7;\">cyterat</a></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57346e9-f842-44a5-8429-7de1d7bd150a",
   "metadata": {},
   "source": [
    "# Practical considerations:\n",
    "\n",
    "- __Data Preparation__: Ensure your data is clean and properly formatted before sampling.\n",
    "\n",
    "- __Sample Size__: Determine an appropriate sample size based on statistical power calculations or practical constraints.\n",
    "\n",
    "- __Randomization__: Use numpy's random number generator for consistency and reproducibility.\n",
    "\n",
    "- __Documentation__: Always document your sampling method and parameters for reproducibility.\n",
    "\n",
    "- __Validation__: Check if your sample is representative of the population using descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf0dc3-5ff4-486c-9dfa-a882cfaf0376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3cd134-803a-4d4b-9224-b6b55688ae2d",
   "metadata": {},
   "source": [
    "# 1. Simple Random Sampling\n",
    "\n",
    "- Randomly sample users for general behavioral analysis.\n",
    "- Select events for performance debugging or anomaly checks.\n",
    "- Create a quick baseline dataset without subgroup constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065da19f-f130-45ec-96a0-e4deb6b486b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_random_sample(data, sample_size, random_state=42):\n",
    "    \"\"\"\n",
    "    Selects a simple random sample of specified size.\n",
    "    \"\"\"\n",
    "    sample = data.sample(n=sample_size, random_state=random_state)\n",
    "    return sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b03169-6439-435c-b3a7-6254a79e8025",
   "metadata": {},
   "source": [
    "# 2. Stratified Sampling\n",
    "\n",
    "- Ensure equal representation of user tiers (e.g., free vs. paid).\n",
    "- Maintain proportional device/platform split (e.g., iOS vs. Android).\n",
    "- Sample feedback forms while preserving demographic diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d077f-f35a-4507-b29e-1831b4d2dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(data, strata_col, frac=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Performs stratified sampling. Each group defined by `strata_col` will be sampled with the same fraction.\n",
    "    \"\"\"\n",
    "    grouped = data.groupby(strata_col, group_keys=False)\n",
    "\n",
    "    def sample_group(group):\n",
    "        return group.sample(frac=frac, random_state=random_state)\n",
    "\n",
    "    stratified = grouped.apply(sample_group)\n",
    "    return stratified.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b71400-ced9-417b-b0dc-875c7bab00b3",
   "metadata": {},
   "source": [
    "# 3. Cluster Sampling\n",
    "\n",
    "- Sample complete user journeys using user_id or session_id.\n",
    "- Analyze full A/B test groups or experiment variants.\n",
    "- Select entire support cases or transaction threads for audit.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a476ffa-35f5-4b91-9139-eb3f9dfa820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_sample(data, cluster_col, n_clusters, random_state=42):\n",
    "    \"\"\"\n",
    "    Samples all data from randomly selected clusters.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    \n",
    "    # Get unique cluster labels\n",
    "    clusters = data[cluster_col].unique()\n",
    "    \n",
    "    # Randomly select clusters\n",
    "    selected_clusters = rng.choice(clusters, n_clusters, replace=False)\n",
    "    \n",
    "    # Filter data for selected clusters\n",
    "    cluster_data = data[data[cluster_col].isin(selected_clusters)]\n",
    "    \n",
    "    return cluster_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a23348d-b5c5-43c8-aa0a-347285ed93c9",
   "metadata": {},
   "source": [
    "# 4. Systematic Sampling\n",
    "\n",
    "- Sample every nth event from an event stream for trend monitoring.\n",
    "- Periodically review logs or metrics from a large dataset.\n",
    "- Analyze recurring patterns in page view sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d525813c-3832-417a-9cc7-299c9cb3ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def systematic_sample(data, step, start=0):\n",
    "    \"\"\"\n",
    "    Selects every `step`-th row starting from index `start`.\n",
    "    \"\"\"\n",
    "    sample = data.iloc[start::step]\n",
    "    return sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3e0d4-a9dc-4042-8fed-cb1ab9a416f5",
   "metadata": {},
   "source": [
    "# 5. Convenience Sampling\n",
    "\n",
    "- Quickly inspect the latest telemetry events or logs.\n",
    "- Pull the first 100 rows for schema or transformation testing.\n",
    "- Prototype analysis without waiting for large data loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde9eb39-4ab9-46a4-8acf-2e3060f5dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convenience_sample(data, sample_size=100):\n",
    "    \"\"\"\n",
    "    Selects the first `sample_size` rows from the dataset.\n",
    "    \"\"\"\n",
    "    sample = data.head(sample_size)\n",
    "    return sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b0e2fa-d4ce-40f6-81ef-6dbcc6fbfe10",
   "metadata": {},
   "source": [
    "# 6. Quota Sampling\n",
    "\n",
    "- Ensure exact counts from each user segment (e.g., 50 paid, 50 free).\n",
    "- Construct samples with fixed proportions of product categories.\n",
    "- Balance country-specific quotas for market surveys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5941d-311f-4ec5-bcf6-2990b92a6cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quota_sample(data, group_col, quotas, random_state=42):\n",
    "    \"\"\"\n",
    "    Samples a fixed number of rows from each group as specified in `quotas`.\n",
    "    \"\"\"\n",
    "    sample = pd.DataFrame()\n",
    "\n",
    "    for group, quota in quotas.items():\n",
    "        group_data = data[data[group_col] == group]\n",
    "        \n",
    "        # Sample with cap in case the group has fewer rows than the quota\n",
    "        selected = group_data.sample(\n",
    "            n=min(len(group_data), quota),\n",
    "            random_state=random_state\n",
    "        )\n",
    "        sample = pd.concat([sample, selected], ignore_index=True)\n",
    "\n",
    "    return sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac6673e-4efb-4017-bb4c-f27fcad09954",
   "metadata": {},
   "source": [
    "# 7. Weighted Sampling\n",
    "\n",
    "- Oversample high-value customers or heavy users.\n",
    "- Emphasize rare but important actions (e.g., cancellations).\n",
    "- Prioritize events with higher business impact for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde94803-aa69-441e-bf61-a207043a33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sample(data, weights_col, n, replace=True, random_state=42):\n",
    "    \"\"\"\n",
    "    Samples `n` rows with probabilities defined by `weights_col`.\n",
    "    \"\"\"\n",
    "    sample = data.sample(\n",
    "        n=n,\n",
    "        weights=data[weights_col],\n",
    "        replace=replace,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    return sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b22ccd-7d82-4a4e-9a7d-a9991dc3cb71",
   "metadata": {},
   "source": [
    "# 8. Time-based Sampling\n",
    "\n",
    "- Extract daily or hourly snapshots from event logs.\n",
    "- Sample data aligned with marketing campaign periods.\n",
    "- Analyze rolling user behavior across time windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3240d62-613f-4378-b781-670462395bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_based_sample(data, freq):\n",
    "    \"\"\"\n",
    "    Resamples time-indexed data at the given frequency.\n",
    "    \"\"\"\n",
    "    if not isinstance(data.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"Data must have a DatetimeIndex for time-based sampling.\")\n",
    "\n",
    "    # Sample the first entry in each time bin\n",
    "    resampled = data.resample(freq).first().dropna()\n",
    "    \n",
    "    return resampled.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955edbca-a584-4c25-8146-4bc80198e43c",
   "metadata": {},
   "source": [
    "# 9. Reservoir Sampling\n",
    "\n",
    "- Sample from streaming data like live logs or events.\n",
    "- Maintain a representative subset from a large or unknown-size dataset.\n",
    "- Create memory-efficient random samples from data pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f271f8-f6d1-4641-9718-8a66a3cc94d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reservoir_sample(iterator, k, random_state=42):\n",
    "    \"\"\"\n",
    "    Selects `k` items from an iterator using reservoir sampling.\n",
    "    Suitable for streaming or very large datasets.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    reservoir = []\n",
    "\n",
    "    for i, item in enumerate(iterator):\n",
    "        if i < k:\n",
    "            reservoir.append(item)\n",
    "        else:\n",
    "            j = rng.integers(0, i + 1)\n",
    "            if j < k:\n",
    "                reservoir[j] = item\n",
    "\n",
    "    return reservoir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87637925-8939-4911-873b-7d36a18e36f0",
   "metadata": {},
   "source": [
    "# Representativeness Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efa963-1f21-4098-aea9-9f8f68034edf",
   "metadata": {},
   "source": [
    "## 1. Descriptive Summary Comparison\n",
    "Compare the key statistics between the full dataset and the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3fa2a-b4bd-49b9-bdc3-04cc9f2a1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_descriptive_stats(full, sample, numeric_cols=None):\n",
    "    \"\"\"\n",
    "    Compares mean and std of numeric columns between full dataset and sample.\n",
    "    \"\"\"\n",
    "    if numeric_cols is None:\n",
    "        numeric_cols = full.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "    print(\"Descriptive Statistics Comparison:\\n\")\n",
    "    for col in numeric_cols:\n",
    "        print(f\"--- {col} ---\")\n",
    "        print(f\"Full     -> Mean: {full[col].mean():.3f}, Std: {full[col].std():.3f}\")\n",
    "        print(f\"Sample   -> Mean: {sample[col].mean():.3f}, Std: {sample[col].std():.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c8dbc-6926-4db4-b8f7-adb8b35ed1d1",
   "metadata": {},
   "source": [
    "## 2. Group Proportion Comparison\n",
    "Use this to verify how well your sample maintains proportions of categorical groups (useful for stratified/quota sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1ffef-d0d4-4622-8065-f1da1d52e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_group_proportions(full, sample, group_col):\n",
    "    \"\"\"\n",
    "    Compares the relative frequency of each group in a column between full dataset and sample.\n",
    "    \"\"\"\n",
    "    full_props = full[group_col].value_counts(normalize=True)\n",
    "    sample_props = sample[group_col].value_counts(normalize=True)\n",
    "\n",
    "    comparison = pd.concat([full_props, sample_props], axis=1)\n",
    "    comparison.columns = ['Full Proportion', 'Sample Proportion']\n",
    "    comparison['Difference'] = (comparison['Sample Proportion'] - comparison['Full Proportion']).abs()\n",
    "\n",
    "    print(f\"Group Proportion Comparison for '{group_col}':\\n\")\n",
    "    print(comparison.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e85ae-ee1b-4e33-9bcf-2aac098115b9",
   "metadata": {},
   "source": [
    "## 3. Distribution Plot Comparison\n",
    "Use histograms or KDE plots to compare numerical distributions visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e4146d-d802-477a-8194-7591b7dabe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def compare_distributions(full, sample, numeric_col, bins=30):\n",
    "    \"\"\"\n",
    "    Plots the distribution of a numeric column in full vs. sample.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(full[numeric_col], color='blue', label='Full', bins=bins, kde=True, stat='density', alpha=0.5)\n",
    "    sns.histplot(sample[numeric_col], color='orange', label='Sample', bins=bins, kde=True, stat='density', alpha=0.5)\n",
    "    plt.title(f'Distribution Comparison: {numeric_col}')\n",
    "    plt.legend()\n",
    "    plt.xlabel(numeric_col)\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10efe865-f71f-41f7-a0f2-1292f375044e",
   "metadata": {},
   "source": [
    "## 4. Sample Integrity Checker\n",
    "Basic utility to confirm sample shape and NaN counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053f45d-53d5-4b0c-aa0e-30077803e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sample_integrity(sample):\n",
    "    \"\"\"\n",
    "    Prints basic info about the sample: shape and missing values.\n",
    "    \"\"\"\n",
    "    print(\"Sample Shape:\", sample.shape)\n",
    "    print(\"Missing Values:\\n\", sample.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb83db-be7a-4931-af67-7e83685933af",
   "metadata": {},
   "source": [
    "## Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab023dca-dcf7-4617-a38d-dee76b76d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_descriptive_stats(data, sample, numeric_cols=['age', 'income'])\n",
    "compare_group_proportions(data, sample, group_col='region')\n",
    "compare_distributions(data, sample, numeric_col='income')\n",
    "check_sample_integrity(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
